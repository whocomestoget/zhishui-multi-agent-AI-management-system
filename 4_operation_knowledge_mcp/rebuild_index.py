#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡å»ºå‘é‡ç´¢å¼•è„šæœ¬
ç”¨äºåœ¨ä¿®å¤æ–‡æœ¬æ ¼å¼åé‡æ–°æ„å»ºFAISSå‘é‡ç´¢å¼•
"""

import sqlite3
import numpy as np
import faiss
import json
import os
from pathlib import Path
import requests
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# é…ç½®
OLLAMA_URL = "http://localhost:11434"
EMBEDDING_MODEL = "qwen3-embedding"
EMBEDDING_DIM = None  # åŠ¨æ€æ£€æµ‹ç»´åº¦

def get_embedding(text):
    """è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º"""
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/embeddings",
            json={
                "model": EMBEDDING_MODEL,
                "prompt": text
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            embedding = np.array(result['embedding'], dtype=np.float32)
            # å½’ä¸€åŒ–å‘é‡
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            return embedding
        else:
            logger.error(f"è·å–å‘é‡å¤±è´¥: {response.status_code}")
            return None
    except Exception as e:
        logger.error(f"è·å–å‘é‡æ—¶å‡ºé”™: {e}")
        return None

def rebuild_vector_index():
    """é‡å»ºå‘é‡ç´¢å¼•"""
    logger.info("å¼€å§‹é‡å»ºå‘é‡ç´¢å¼•...")
    
    # è¿æ¥æ•°æ®åº“
    db_path = "knowledge_base/metadata.db"
    if not os.path.exists(db_path):
        logger.error(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return False
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    
    try:
        # è·å–æ‰€æœ‰æ–‡æ¡£å—
        cursor = conn.execute("""
            SELECT chunk_id, content 
            FROM document_chunks 
            ORDER BY chunk_id
        """)
        
        chunks = cursor.fetchall()
        logger.info(f"æ‰¾åˆ° {len(chunks)} ä¸ªæ–‡æ¡£å—")
        
        if not chunks:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£å—")
            return False
        
        # åˆ›å»ºFAISSç´¢å¼•ï¼ˆåŠ¨æ€æ£€æµ‹ç»´åº¦ï¼‰
        index = None
        chunk_mapping = {}
        
        # å¤„ç†æ¯ä¸ªæ–‡æ¡£å—
        for i, chunk in enumerate(chunks):
            chunk_id = chunk['chunk_id']
            content = chunk['content']
            
            if not content or not content.strip():
                logger.warning(f"è·³è¿‡ç©ºå†…å®¹çš„å—: {chunk_id}")
                continue
            
            # è·å–å‘é‡
            embedding = get_embedding(content)
            if embedding is None:
                logger.warning(f"æ— æ³•è·å–å— {chunk_id} çš„å‘é‡")
                continue
            
            # ç¬¬ä¸€æ¬¡è·å–å‘é‡æ—¶åˆå§‹åŒ–ç´¢å¼•
            if index is None:
                embedding_dim = len(embedding)
                logger.info(f"æ£€æµ‹åˆ°å‘é‡ç»´åº¦: {embedding_dim}")
                index = faiss.IndexFlatIP(embedding_dim)
            
            # æ·»åŠ åˆ°ç´¢å¼•
            index.add(embedding.reshape(1, -1))
            chunk_mapping[index.ntotal - 1] = chunk_id
            
            if (i + 1) % 10 == 0:
                logger.info(f"å·²å¤„ç† {i + 1}/{len(chunks)} ä¸ªæ–‡æ¡£å—")
        
        # ä¿å­˜ç´¢å¼•
        vectors_dir = Path("knowledge_base/vectors")
        vectors_dir.mkdir(exist_ok=True)
        
        index_file = vectors_dir / "faiss.index"
        mapping_file = vectors_dir / "chunk_mapping.json"
        
        # ä¿å­˜FAISSç´¢å¼•
        faiss.write_index(index, str(index_file))
        
        # ä¿å­˜æ˜ å°„å…³ç³»
        with open(mapping_file, 'w', encoding='utf-8') as f:
            json.dump(chunk_mapping, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å‘é‡ç´¢å¼•é‡å»ºå®Œæˆï¼")
        logger.info(f"- ç´¢å¼•æ–‡ä»¶: {index_file}")
        logger.info(f"- æ˜ å°„æ–‡ä»¶: {mapping_file}")
        logger.info(f"- æ€»å‘é‡æ•°: {index.ntotal}")
        
        return True
        
    except Exception as e:
        import traceback
        logger.error(f"é‡å»ºç´¢å¼•æ—¶å‡ºé”™: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return False
    finally:
        conn.close()

if __name__ == "__main__":
    print("=== å‘é‡ç´¢å¼•é‡å»ºå·¥å…· ===")
    print("æ­¤å·¥å…·å°†ä½¿ç”¨ä¿®å¤åçš„æ–‡æœ¬å†…å®¹é‡æ–°æ„å»ºå‘é‡ç´¢å¼•")
    print()
    
    # æ£€æŸ¥OllamaæœåŠ¡
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        if response.status_code != 200:
            print("âŒ OllamaæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
            exit(1)
    except:
        print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ï¼Œè¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ")
        exit(1)
    
    print("âœ… OllamaæœåŠ¡æ­£å¸¸")
    
    # å¼€å§‹é‡å»º
    success = rebuild_vector_index()
    
    if success:
        print("\nğŸ‰ å‘é‡ç´¢å¼•é‡å»ºæˆåŠŸï¼")
        print("ç°åœ¨å¯ä»¥æµ‹è¯•æœç´¢åŠŸèƒ½äº†")
    else:
        print("\nâŒ å‘é‡ç´¢å¼•é‡å»ºå¤±è´¥")
        exit(1)